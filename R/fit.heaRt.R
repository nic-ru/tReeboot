#' Fit statistical and machine learning models to heart disease data
#'
#' Fits several statistical and machine learning models to heart disease
#' data previously loaded with \code{\link{load_heaRt}}. The response
#' variable is the binary diagnosis indicator \code{y}, while one or two
#' clinical predictors are used as explanatory variables.
#'
#' The function is implemented as an S3 generic, with a dedicated method
#' for objects of class \code{"heaRt"}.
#'
#' @usage
#' fit(
#'   obj,
#'   num_var = c("1", "2"),
#'   fit_type = c("decision.tree", "logistic.reg", "random.forest", "lm"),
#'   consider_first = TRUE,
#'   ...
#' )
#'
#' @arguments
#' \item{obj}{An object of class \code{"heaRt"} generated by
#'   \code{\link{load_heaRt}}.}
#'
#' \item{num_var}{The number of predictors to be used in the model.
#'   Either \code{"1"} or \code{"2"}.}
#'
#' \item{fit_type}{The type of model to be fitted. Possible choices are
#'   decision trees (\code{"decision.tree"}), logistic regression
#'   (\code{"logistic.reg"}), random forests (\code{"random.forest"}),
#'   or linear regression (\code{"lm"}).}
#'
#' \item{consider_first}{Logical. When two predictors are available and
#'   \code{num_var = "1"}, determines whether the first or the second
#'   predictor is used. Defaults to \code{TRUE}.}
#'
#' \item{...}{Catches unused arguments to \code{fit}.}
#'
#' @value
#' An object of class \code{"heaRt_fit"} containing the fitted model,
#' the data used for fitting, and the selected \code{fit_type}.
#'
#' @description
#' Fits decision tree, logistic regression, random forest, or linear
#' regression models to heart disease data. The function automatically
#' constructs the appropriate model formula based on the selected options,
#' removing the need for manual specification by the user.
#'
#' @note
#' A dedicated \code{\link[=plot.heaRt_fit]{plot}} method is provided for
#' objects of class \code{"heaRt_fit"}, which produces model-specific
#' visualisations.
#'
#' @examples
#' dat <- load_heaRt(vars = "rbp-restECG")
#'
#' # Fit different models to the same data
#' mod1 <- fit(dat, num_var = "2", fit_type = "decision.tree")
#' mod2 <- fit(dat, num_var = "2", fit_type = "random.forest")
#' mod3 <- fit(dat, num_var = "1", fit_type = "lm")
#' mod4 <- fit(dat, num_var = "2",
#'             fit_type = "logistic.reg",
#'             consider_first = FALSE)
#'
#' @seealso
#' \code{\link{load_heaRt}}, \code{\link{plot.heaRt_fit}},
#' \code{\link[stats]{lm}}, \code{\link[stats]{glm}},
#' \code{\link[rpart]{rpart}}, \code{\link[randomForest]{randomForest}}
#'
#' @export


fit <- function(obj, num_var = c("1", "2"),
                fit_type = c("decision.tree", "logistic.reg", "random.forest", "lm"),
                consider_first = TRUE, ...) {
  UseMethod("fit")
}

#' @export
fit.heaRt <- function(obj, num_var = c("1", "2"),
                         fit_type = c("decision.tree", "logistic.reg", "random.forest", "lm"),
                         consider_first = TRUE, ...) {

  # ensure the input is of class "heaRt"
  if(!inherits(obj, "heaRt"))
    stop("This function only works on objects of class \"heaRt\"")

  # with the param "num_var" the user can choose the number of variable in the model(up to two)
  # and with the param "consider_first" can choose if considering the first of the two or no

  num_var <- match.arg(num_var)

  # choosing the type of fitting model
  fit_type = match.arg(fit_type)

  y <- obj$y
  var1 <- obj[[2]]
  var2 <- obj[[3]]

  data <- switch(num_var,
                 "1" = {
                   data.frame(y = y, var1 = var1)},
                 "2" = {
                   data.frame(y = y, var1 = var1, var2 = var2)})

  if(consider_first == FALSE)
    data <- data |> dplyr::select(y, var2) |> dplyr::rename(var1 = var2)
  # easier to plot the random forest

  # fitting the model

  if(num_var == "1")
    mod <- switch(fit_type,
                  decision.tree = {
                    data |> rpart::rpart(y ~ var1, data = _)
                  },
                  logistic.reg = {
                    data |> stats::glm(y ~ var1, family = stats::binomial(link = "logit"), data = _)
                  },
                  random.forest = {
                    data |> randomForest::randomForest(y ~ var1, data = _)
                  },
                  lm = {
                    data |> stats::lm(y ~ var1, data = _)
                  })

  if(num_var == "2" & consider_first == TRUE)
    mod <- switch(fit_type,
                  decision.tree = {
                    data |> rpart::rpart(y ~ var1 + var2, data = _)
                  },
                  logistic.reg = {
                    data |> stats::glm(y ~ var1 + var2, family = stats::binomial(link = "logit"),
                                       data = _)
                  },
                  random.forest = {
                    data |> randomForest::randomForest(y ~ var1 + var2, data = _)
                  },
                  lm = {
                    data |> stats::lm(y ~ var1 + var2, data = _)
                  })

  if(num_var == "2" & consider_first == FALSE)
    mod <- switch(fit_type,
                  decision.tree = {
                    data |> rpart::rpart(y ~ var2, data = _)
                  },
                  logistic.reg = {
                    data |> stats::glm(y ~ var2, family = stats::binomial(link = "logit"), data = _)
                  },
                  random.forest = {
                    data |> randomForest::randomForest(y ~ var2,data = _)
                  },
                  lm = {
                    data |> stats::lm(y ~ var2, data = _)
                  })


  print(mod)

  output <- list(model = mod,
                 data = data,
                 fit_type = fit_type,
                 method = NULL)
  attr(output, "source") <- attr(obj, "source")

  # checking if the fitted model is either a decision tree or a random forest,
  # it'll be useful when plotting
  if(fit_type %in% c("decision.tree", "random.forest"))
    output$method <- "class"

  class(output) <- c("heaRt_fit",
                     class(mod),
                     "listof")

  invisible(output)

}
